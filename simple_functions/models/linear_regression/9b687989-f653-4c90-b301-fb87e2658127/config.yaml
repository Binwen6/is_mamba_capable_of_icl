config: conf/linear_regression_gpt2.yaml
inherit:
- /workspace/code/is_mamba_capable_of_icl/simple_functions/src/conf/base.yaml
model:
  family: gpt2
  n_dims: 20
  n_embd: 256
  n_head: 8
  n_layer: 12
  n_positions: 2048
  remove_pos_embedding: true
out_dir: ../models/linear_regression/9b687989-f653-4c90-b301-fb87e2658127
test_run: false
training:
  batch_size: 64
  curriculum:
    dims:
      end: 20
      inc: 1
      interval: 2000
      start: 5
    points:
      end: 41
      inc: 2
      interval: 2000
      start: 11
  data: gaussian
  data_kwargs: {}
  keep_every_steps: 100000
  learning_rate: 0.0001
  learning_rate_schedule: cosine
  num_tasks: null
  num_training_examples: null
  resume_id: null
  save_every_steps: 1000
  seed: 2
  task: linear_regression
  task_kwargs: {}
  train_steps: 500001
wandb:
  entity: in-context-mamba
  log_every_steps: 100
  name: linear_regression_standard
  notes: ''
  project: in-context-mamba
